"""
Integration test demonstrating the end-to-end ingestion workflow.

This test validates that:
1. Text can be ingested with proper metadata
2. Entities are extracted and stored in ArangoDB
3. Chunks are embedded and stored in Qdrant (when available)
4. The retrieval system can find relevant information

User Story: As a legal researcher, I want to ingest a legal document
and have it automatically indexed so tenants can find relevant information.
"""
import os
import pytest
from datetime import datetime

from tenant_legal_guidance.graph.arango_graph import ArangoDBGraph
from tenant_legal_guidance.services.document_processor import DocumentProcessor
from tenant_legal_guidance.services.tenant_system import TenantLegalSystem
from tenant_legal_guidance.services.retrieval import HybridRetriever
from tenant_legal_guidance.models.entities import (
    SourceMetadata,
    SourceType,
    SourceAuthority,
    LegalDocumentType,
    EntityType,
)


# Sample legal text about rent stabilization
SAMPLE_LEGAL_TEXT = """
NYC Administrative Code § 26-504: Rent increases for rent stabilized apartments

(a) Rent increases for rent stabilized apartments shall be governed by the Rent Guidelines Board.
The Board shall establish maximum rates of rent increase which shall be applicable to 
dwelling units subject to this law.

(b) No owner may charge rent in excess of the lawful regulated rent. Owners found to have
collected rent in excess of the legal regulated rent shall be liable to the tenant for 
three times the overcharge, reasonable attorney's fees, and interest.

(c) Tenants in rent stabilized apartments have the right to receive proper notice before
any rent increase takes effect. The notice must be provided at least 60 days before 
the lease renewal date for rent increases over 5%.
"""


@pytest.fixture(scope="module")
def clean_test_db():
    """Reset the test database before running tests."""
    # Only run if explicitly enabled to avoid accidental data loss
    if os.getenv("ENABLE_TEST_DB_RESET") != "true":
        pytest.skip("Set ENABLE_TEST_DB_RESET=true to run integration tests with DB reset")
    
    kg = ArangoDBGraph()
    stats_before = kg.get_database_stats()
    print(f"\n📊 Database stats before test: {stats_before}")
    
    # Reset if there's existing data
    if sum(stats_before.values()) > 0:
        print("🗑️  Resetting database for clean test...")
        kg.reset_database(confirm=True)
    
    yield kg
    
    stats_after = kg.get_database_stats()
    print(f"\n📊 Database stats after test: {stats_after}")


@pytest.mark.integration
@pytest.mark.asyncio
async def test_ingest_legal_document_creates_entities(clean_test_db):
    """
    User Story: Ingest a rent stabilization statute and verify entities are created.
    
    This demonstrates that legal text → entities → database workflow works.
    """
    kg = clean_test_db
    processor = DocumentProcessor(kg)
    
    # Create metadata for the document
    metadata = SourceMetadata(
        source="https://codelibrary.amlegal.com/codes/newyorkcity/latest/NYCadmin/0-0-0-26504",
        source_type=SourceType.URL,
        authority=SourceAuthority.BINDING_LEGAL_AUTHORITY,
        document_type=LegalDocumentType.STATUTE,
        organization="NYC Council",
        title="NYC Admin Code § 26-504 - Rent Increases",
        jurisdiction="NYC",
        processed_at=datetime.utcnow(),
        attributes={"tags": '["rent_stabilization", "rent_increase", "overcharge"]'}
    )
    
    # Ingest the document
    result = await processor.ingest_document(
        text=SAMPLE_LEGAL_TEXT,
        metadata=metadata,
        force_reprocess=True  # Ensure we process even if source exists
    )
    
    # Verify ingestion succeeded
    assert result["status"] in ["success", "partial_success"], f"Ingestion failed: {result}"
    assert result["added_entities"] > 0, "Should have extracted at least one entity"
    
    print(f"\n✅ Ingestion result: {result['added_entities']} entities, {result['chunk_count']} chunks")
    
    # Verify entities are in database
    stats = kg.get_database_stats()
    assert stats.get("entities", 0) > 0, "Should have entities in database"
    assert stats.get("sources", 0) > 0, "Should have source record in database"
    
    print(f"📊 Created {stats['entities']} entities, {stats['sources']} sources")


@pytest.mark.integration
@pytest.mark.asyncio
async def test_ingest_is_idempotent(clean_test_db):
    """
    User Story: Re-ingesting the same document should be idempotent (no duplicates).
    
    This validates the SHA256-based duplicate detection.
    """
    kg = clean_test_db
    processor = DocumentProcessor(kg)
    
    metadata = SourceMetadata(
        source="https://example.com/test-statute",
        source_type=SourceType.URL,
        authority=SourceAuthority.BINDING_LEGAL_AUTHORITY,
        document_type=LegalDocumentType.STATUTE,
        title="Test Statute for Idempotency",
        jurisdiction="NYC",
        processed_at=datetime.utcnow(),
    )
    
    # First ingestion
    result1 = await processor.ingest_document(
        text=SAMPLE_LEGAL_TEXT,
        metadata=metadata,
        force_reprocess=False
    )
    entities_count_1 = result1["added_entities"]
    source_sha_1 = result1.get("sha256")
    
    # Second ingestion (should skip)
    result2 = await processor.ingest_document(
        text=SAMPLE_LEGAL_TEXT,
        metadata=metadata,
        force_reprocess=False
    )
    
    # Verify second ingestion was skipped
    assert result2["status"] == "skipped", "Second ingestion should be skipped"
    assert result2["reason"] == "already_processed", "Should skip due to duplicate content"
    assert result2.get("sha256") == source_sha_1, "SHA256 should match"
    
    # Verify database has same number of entities (no duplicates)
    stats = kg.get_database_stats()
    print(f"\n✅ Idempotency verified: {result2['status']}, SHA256: {source_sha_1[:12]}...")
    print(f"📊 Database stable at {stats['entities']} entities, {stats['sources']} sources")


@pytest.mark.integration
@pytest.mark.asyncio
async def test_retrieval_finds_ingested_content(clean_test_db):
    """
    User Story: After ingesting legal content, tenants should be able to
    search and find relevant information for their case.
    
    This validates the full pipeline: ingest → store → retrieve.
    """
    kg = clean_test_db
    
    # Step 1: Ingest content
    processor = DocumentProcessor(kg)
    metadata = SourceMetadata(
        source="https://example.com/rent-stabilization-guide",
        source_type=SourceType.URL,
        authority=SourceAuthority.PRACTICAL_SELF_HELP,
        document_type=LegalDocumentType.SELF_HELP_GUIDE,
        title="Rent Stabilization Guide",
        jurisdiction="NYC",
        processed_at=datetime.utcnow(),
    )
    
    await processor.ingest_document(
        text=SAMPLE_LEGAL_TEXT,
        metadata=metadata,
        force_reprocess=True
    )
    
    # Step 2: Search for relevant information
    retriever = HybridRetriever(kg)
    
    # Test entity search (should work even without Qdrant)
    entity_results = kg.search_entities_by_text("rent stabilization", limit=10)
    assert len(entity_results) > 0, "Should find entities related to 'rent stabilization'"
    
    print(f"\n🔍 Entity search found {len(entity_results)} entities:")
    for e in entity_results[:3]:
        print(f"   - {e.entity_type.value}: {e.name[:60]}")
    
    # Test hybrid retrieval (will attempt vector search)
    try:
        results = retriever.retrieve("My landlord increased my rent illegally", top_k_chunks=5, top_k_entities=10)
        
        print(f"\n🔍 Hybrid retrieval found:")
        print(f"   - {len(results['chunks'])} chunks")
        print(f"   - {len(results['entities'])} entities")
        print(f"   - {len(results.get('neighbors', []))} neighbors")
        
        # At minimum, should find entities even if chunks fail
        assert len(results['entities']) > 0, "Should find at least one relevant entity"
        
    except Exception as e:
        # If Qdrant is not available or fails, that's a known issue
        print(f"\n⚠️  Hybrid retrieval failed (expected if Qdrant unavailable): {e}")
        print("   Entity search still works, demonstrating partial functionality")


@pytest.mark.integration
def test_database_management_tools():
    """
    User Story: As a developer, I need to be able to inspect and reset
    the database state for testing and debugging.
    
    This validates the database management utilities.
    """
    if os.getenv("ENABLE_TEST_DB_RESET") != "true":
        pytest.skip("Set ENABLE_TEST_DB_RESET=true to run DB management tests")
    
    kg = ArangoDBGraph()
    
    # Test stats retrieval
    stats = kg.get_database_stats()
    assert isinstance(stats, dict), "Should return stats dictionary"
    assert "entities" in stats, "Should include entities collection"
    assert "sources" in stats, "Should include sources collection"
    
    print(f"\n📊 Database stats: {stats}")
    
    # Test reset (if database has data)
    if stats.get("entities", 0) > 0:
        deleted = kg.reset_database(confirm=True)
        assert isinstance(deleted, dict), "Should return deleted counts"
        
        # Verify reset worked
        stats_after = kg.get_database_stats()
        assert stats_after.get("entities", 0) == 0, "Should have 0 entities after reset"
        
        print(f"🗑️  Reset database: deleted {deleted}")


if __name__ == "__main__":
    # Allow running this test file directly for debugging
    print("To run these integration tests:")
    print("  export ENABLE_TEST_DB_RESET=true")
    print("  pytest tests/integration/test_ingestion_workflow.py -v -s")

